{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0001,\n",
       " 0.0002,\n",
       " 0.0003,\n",
       " 0.0004,\n",
       " 0.0005,\n",
       " 0.0006,\n",
       " 0.0007,\n",
       " 0.0008,\n",
       " 0.0009,\n",
       " 0.001,\n",
       " 0.0011,\n",
       " 0.0012,\n",
       " 0.0013,\n",
       " 0.0014,\n",
       " 0.0015,\n",
       " 0.0016,\n",
       " 0.0017,\n",
       " 0.0018,\n",
       " 0.0019]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(i*1e-4,4) for i in range(0, 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swap de Casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Running time 0:00:00\n"
     ]
    }
   ],
   "source": [
    "from CBR import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = eval(generate_new_problem())\n",
    "p2 = eval(generate_new_problem())\n",
    "\n",
    "df_problemes = pd.read_csv('./data/problems4000_not_0_0_0.csv')\n",
    "rs = createRS(from_model= False, casebase=df_problemes, maxcasesxleaf=10)\n",
    "\n",
    "c1 = Cas(id=1,descripcio=rs.scaler.transform([p1.array])[0])\n",
    "c2 = Cas(id=2,descripcio=rs.scaler.transform([p2.array])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 1,\n",
       "  'descripcio': array([0.5       , 0.8       , 0.6       , 0.        , 0.33333333,\n",
       "         0.1       , 0.77777778, 0.2       , 1.11111111, 1.        ,\n",
       "         0.00371287, 0.06284658, 0.32683374]),\n",
       "  'derivacio': set(),\n",
       "  'solucio': [],\n",
       "  'avaluacio': [],\n",
       "  'historial': [],\n",
       "  'cops_us': 0,\n",
       "  'mesura_utilitat': None,\n",
       "  'UM': 0,\n",
       "  'UaS': 0,\n",
       "  'S': 0,\n",
       "  'UaF': 0,\n",
       "  'F': 0,\n",
       "  'ultim': False},\n",
       " {'id': 2,\n",
       "  'descripcio': array([ 0.6       ,  0.1       ,  0.4       , -0.16666667,  0.77777778,\n",
       "          1.        ,  1.        ,  0.2       ,  0.55555556,  0.88888889,\n",
       "          0.13242574,  0.0189464 ,  0.45885109]),\n",
       "  'derivacio': set(),\n",
       "  'solucio': [],\n",
       "  'avaluacio': [],\n",
       "  'historial': [],\n",
       "  'cops_us': 0,\n",
       "  'mesura_utilitat': None,\n",
       "  'UM': 0,\n",
       "  'UaS': 0,\n",
       "  'S': 0,\n",
       "  'UaF': 0,\n",
       "  'F': 0,\n",
       "  'ultim': False})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.__dict__,c2.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.__dict__, c2.__dict__ = c2.__dict__.copy(), c1.__dict__.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 2,\n",
       "  'descripcio': array([ 0.6       ,  0.1       ,  0.4       , -0.16666667,  0.77777778,\n",
       "          1.        ,  1.        ,  0.2       ,  0.55555556,  0.88888889,\n",
       "          0.13242574,  0.0189464 ,  0.45885109]),\n",
       "  'derivacio': set(),\n",
       "  'solucio': [],\n",
       "  'avaluacio': [],\n",
       "  'historial': [],\n",
       "  'cops_us': 0,\n",
       "  'mesura_utilitat': None,\n",
       "  'UM': 0,\n",
       "  'UaS': 0,\n",
       "  'S': 0,\n",
       "  'UaF': 0,\n",
       "  'F': 0,\n",
       "  'ultim': False},\n",
       " {'id': 1,\n",
       "  'descripcio': array([0.5       , 0.8       , 0.6       , 0.        , 0.33333333,\n",
       "         0.1       , 0.77777778, 0.2       , 1.11111111, 1.        ,\n",
       "         0.00371287, 0.06284658, 0.32683374]),\n",
       "  'derivacio': set(),\n",
       "  'solucio': [],\n",
       "  'avaluacio': [],\n",
       "  'historial': [],\n",
       "  'cops_us': 0,\n",
       "  'mesura_utilitat': None,\n",
       "  'UM': 0,\n",
       "  'UaS': 0,\n",
       "  'S': 0,\n",
       "  'UaF': 0,\n",
       "  'F': 0,\n",
       "  'ultim': False})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.__dict__,c2.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proves maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.1,\n",
       " 49.2,\n",
       " 49.3,\n",
       " 49.4,\n",
       " 49.5,\n",
       " 49.6,\n",
       " 49.7,\n",
       " 49.8,\n",
       " 49.9,\n",
       " 50.0,\n",
       " 50.1,\n",
       " 50.2,\n",
       " 50.3,\n",
       " 50.4,\n",
       " 50.5,\n",
       " 50.6,\n",
       " 50.7,\n",
       " 50.8,\n",
       " 50.9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[49 + 0.1*i for i in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64,activation='relu')) #layer 3\n",
    "model.add(Dense(num_classes,activation = 'softmax')) #layer 4\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train, y_train_one_hot, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot, batch_size=batch_size)\n",
    "print(f\"Test accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter([2,2,2,3,4,4,4,4])\n",
    "print(c.most_common(2))\n",
    "mc = [m[0] for m in c.most_common(2)]\n",
    "print(mc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Supongamos que queremos 2 clústers\n",
    "n_clusters = 2\n",
    "\n",
    "# Generamos algunos datos aleatorios como ejemplo\n",
    "# Aquí, estamos generando 50 casos, cada uno con 2 características\n",
    "np.random.seed(0)\n",
    "casos = np.random.rand(50, 2)\n",
    "\n",
    "# Aplicamos el algoritmo KMeans\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init='auto')\n",
    "kmeans.fit([cas for cas in casos])\n",
    "\n",
    "# Almacenamos los centroides de los clústers\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Dividimos los casos según las etiquetas del clustering\n",
    "cluster1 = [casos[i] for i in range(len(casos)) if kmeans.labels_[i] == 0]\n",
    "cluster2 = [casos[i] for i in range(len(casos)) if kmeans.labels_[i] == 1]\n",
    "\n",
    "# Para verificar, mostramos los primeros 5 casos de cada clúster\n",
    "(cluster1[:5], cluster2[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=None\n",
    "a=+None\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self) -> None:\n",
    "        self.t = 8\n",
    "        self.x = 2\n",
    "        self.y = 'a'\n",
    "        self.z = 'd'\n",
    "\n",
    "a = A()\n",
    "print(a.__dict__)\n",
    "\n",
    "for k,v in a.__dict__.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Carga tus datos aquí (debes tener tus datos en forma de matriz o DataFrame)\n",
    "\n",
    "data = np.array([[2, 3],\n",
    "                 [3, 3],\n",
    "                 [3, 4],\n",
    "                 [6, 5],\n",
    "                 [6, 4],\n",
    "                 [7, 5],\n",
    "                 [8, 7],\n",
    "                 [8, 8],\n",
    "                 [9, 6],\n",
    "                 [9, 9]])\n",
    "\n",
    "# Aplicar Hierarchical Clustering con distancia euclidiana y método Ward\n",
    "models = []\n",
    "\n",
    "kmeans = KMeans(n_clusters=2,random_state=0)\n",
    "kmeans.fit(data)\n",
    "\n",
    "cluster1 = data[kmeans.labels_ == 0]\n",
    "cluster2 = data[kmeans.labels_ == 1]\n",
    "\n",
    "\n",
    "models.append(kmeans)\n",
    "\n",
    "cluster1 = data[kmeans.labels_== 0]\n",
    "cluster2 = data[kmeans.labels_== 1]\n",
    "new_data = np.array([[2,1]])\n",
    "predictions = kmeans.predict(new_data)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2,random_state=0)\n",
    "kmeans.fit(cluster1)\n",
    "\n",
    "models.append(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].predict([[2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(3):\n",
    "\n",
    "kmeans = KMeans(n_clusters=2,random_state=i)\n",
    "kmeans.fit(data)\n",
    "\n",
    "models.append(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Guardar los objetos de clustering en archivos\n",
    "with open(\"clustering1.pkl\", \"wb\") as f1:\n",
    "    pickle.dump(clustering1, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Cambia a 1 si quieres comenzar la numeración desde 1\n",
    "datos_etiqueta_1 = data[kmeans.labels_\n",
    "                        == 0]\n",
    "datos_etiqueta_2 = data[kmeans.labels_\n",
    "                        == 1]  # Cambia a 2 en consecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_etiqueta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(casos, method='ward', metric='euclidean')\n",
    "clusters = fcluster(Z, 2, criterion='maxclust')\n",
    "casos_etiqueta_1 = casos[np.where(clusters == 1)]\n",
    "casos_etiqueta_2 = casos[np.where(clusters == 2)]\n",
    "\n",
    "self.left.creaccio(casos_etiqueta_1)\n",
    "self.righ.creaccio(casos_etiqueta_2)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dades practica 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data\\problems.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom1 = [eval(i) for i in df['recomendations'].tolist()]\n",
    "recom2 = [eval(i) for i in df['recom_ratings'].tolist()]\n",
    "\n",
    "recom2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo JSON con el diccionario\n",
    "file_path = './data/books_dict.json'\n",
    "\n",
    "# Función para cargar el diccionario desde un archivo JSON\n",
    "def cargar_diccionario(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "books_dict = cargar_diccionario(file_path)\n",
    "book_ids = list(books_dict.keys())\n",
    "print(book_ids[:5])\n",
    "book_titles = list(books_dict.values())\n",
    "\n",
    "problems = pd.read_csv('./data/problems.csv')\n",
    "read_books_set = set(book for books_list in problems['read_books'].apply(eval) for book in books_list)\n",
    "print(read_books_set)\n",
    "\n",
    "filtered_books_dict = {book_id: books_dict[book_id] for book_id in read_books_set if str(book_id) in books_dict}\n",
    "print(filtered_books_dict)\n",
    "\n",
    "output_file_path = './data/books_dict_clean.json'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(filtered_books_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pd.read_csv('data/problems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.drop(['read_books','recomendations','recom_ratings'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\Escritorio\\casebooks_SBC\\interactions.csv') \n",
    "#aqui es directori adient ja que no hi cap a github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['is_read','is_reviewed'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pr.merge(df[['user_id', 'book_id', 'rating']], on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merged.drop(['rating','user_id'],axis=True)\n",
    "X['book_id'] = X['book_id'].astype('category')\n",
    "y = df_merged['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr()\n",
    "corr.style.background_gradient(cmap='RdYlBu').set_precision(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo de árbol de decisiones\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnes = X.columns\n",
    "model = DecisionTreeClassifier(max_depth=8, random_state=10)\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred\n",
    "y_testid = y_test.to_numpy()\n",
    "print(classification_report(y_pred,y_test))\n",
    "\n",
    "plt.figure(figsize=(30,12))  # set plot size (denoted in inches)\n",
    "plot_tree(model, fontsize=10, feature_names = columnes, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalMaxPooling1D, Conv1D, GlobalAveragePooling1D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
